\documentclass[article]{jss}

%%\VignetteIndexEntry{Causal Inference: The pcalg R package}
%%\VignetteDepends{}
\SweaveOpts{engine=R,eps=FALSE,pdf=TRUE,width=7,height=4}
\SweaveOpts{keep.source=TRUE,strip.white=TRUE}
%           ^^^^^^^^^^^^^^^^ preserve comments (and all) in R chunks

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Markus Kalisch\\ETH Z\"urich \And
        Martin M\"achler\\ETH Z\"urich \And
      Diego Colombo\\ETH Z\"urich \And
    Marloes H. Maathuis\\ETH Z\"urich \And
  Peter B\"uhlmann\\ETH Z\"urich}
\title{Causal Inference using Graphical Models with the Package \pkg{pcalg}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Markus Kalisch, Martin M\"achler, Diego Colombo, Marloes
  H. Maathuis, Peter B\"uhlmann} %% comma-separated
\Plaintitle{Causal Inference using Graphical Models: The package pcalg} %% without formatting
\Shorttitle{Causal Inference} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
  The abstract of the article.
}
\Keywords{keywords, comma-separated, not capitalized, \proglang{R}}
\Plainkeywords{keywords, comma-separated, not capitalized, R} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Markus Kalisch\\
  Seminar f\"ur Statistik\\
  ETH Z\"urich\\
  8092 Z\"urich, Switzerland\\
  E-mail: \email{kalisch@stat.math.ethz.ch}\\
  %% URL: \url{http://stat.ethz.ch/people/kalisch}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}


%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section{Introduction}
THIS DOCUMENTATION IS STILL UNDER CONSTRUCTION! \\

Understanding cause-effect relationships between variables is of primary
interest in many fields of science. Usually, experimental intervention is
used to find these relationships. In many settings, however, experiments
are infeasible because of time, cost or ethical constraints.

Recently, we proposed and mathematically justified a statistical
method (IDA) to obtain bounds on total causal effects based solely on
observational data [ANNALS]. Futhermore, we recently presented an experimental
validation of our method on a large-scale biological system [NATURE METHODS].

For further validation and broader use of this method, well documented and
easy to use software is indispensible. Therefore, we wrote the R package
\pkg{pcalg}, which incorporates the above mentioned method (IDA).

The objective of this paper is to introduce the R package \pkg{pcalg} and
explain the main range of functions.

To get started quickly, we showi how two of the main functions can be used
in a typical application. Suppose we have a system consisting of variables
and many observations of this system. Furthermore, it seems plausible, that
there are no hidden variables and no feedback loops in the underlying
causal system. We are interested in the change of variable Y if we changed
the variable X by intervention, i.e., we seek the causal effect of X on Y.
To fix ideas, we have simulated an examle data set with $p = 8$ continuous
variables with gaussian noise and $n = 5000$ observations, which we will
now analyse. First, we load the data set.

%%- 
%%- <<exIntro1>>=
%%- library(pcalg, lib.loc = "/u/kalisch/research/packages/pcalg.Rcheck")
%%- ## load data
%%- data(gaussianData)
%%- @

In the next step, we use the function \code{pc} to produce an estimate of
the underlying causal structure. Since this function is based on
conditional independence tests, we need to define two things: First, a
function that can compute conditional independence tests in a way that is
suitable for the data at hand. For standard data types (gaussian, discrete
and gaussian) we provide predefined functions which you can use. See the
example section in the help file of \code{pc}. Secondly, we need a summary
of the data (sufficient statistic) on which the conditional independence
function can work. Each conditional independence test can be performed at a
certain significance level \texttt{alpha}. This can be treated as a tuning
parameter.
%%- 
%%- <<exIntro2>>=
%%- ## use predefined test for conditional independence on gaussian data
%%- indepTest <- gaussCItest 
%%- ## the functin gaussCItest needs as input the correlation matrix C and 
%%- ## the sample size n
%%- suffStat <- list(C = cor(dat), n = 5000)
%%- ## estimate the causal structure
%%- pc.fit <- pc(suffStat, indepTest, p = 8, alpha = 0.01)
%%- @ 
%%- <<exIntroPlot>>=
%%- ## plot the resulting causal structure
%%- plot(pc.fit)
%%- @ 

As can be seen in the plot, there are directed and bidirected edges in the
estimated causal structure. The directed edges show the presence and
direction of direct causal effects. The direction of the bidirected edges,
however, could not be decided by our method. Thus, they represent some
uncertainty in the resulting model. A fundamental property of our method
is, that some uncertainty of this kind sometimes remains, even if an
infinite amount of data is available.

Based on the inferred causal structure, we can estimate the causal
effect of an intervention. Suppose, we would increase variable 1 by
one unit, how much would variable 6 increase? Since the causal structure
was not identified perfectly, we cannot expect to get a unique
number. Instead, we will get a set of possible causal effects. This set can
be computed by using the function \code{ida}.
%%- 
%%- <<exIntro2>>=
%%- ida(1, 6, cov(dat), pc.fit@graph)
%%- @ 

Since we simulated the data, we know that the true value of the causal
effect is 0.296. Thus, one of the two estimates is indeed close to the true
value. Since both values are larger than zero, we can conclude, that
variable 1 has a positive causal effect on variable 6 (note that we have no
p-value to control the sampling error).

If we would like to know the effect of a unit increase in variable 1 on
variables 3, 5 and 6, we could simply call \code{ida} three times. However,
a faster way is to call the function \code{idaFast}, which was taylored for
such situations. Each row shows the set of effects on the target variable
indicated by the row names.
%%- 
%%- <<exIntro3>>=
%%- idaFast(1, c(3,5,6), cov(dat), pc.fit@graph)
%%- @ 

The true values for the causal effects are 0.441, 0, 0.296 for variables
3, 5 and 6, respectively. The first row of the output, corresponding to
variable 3, is uninformative. Although one entry comes close to the true
value, the other estimate is 0. Thus, we cannot be sure if there is a
causal effect at all. The second row, corresponding to variable 5, quite
accurately indicates a causal effect that is very close to zero. The third
row, corresponding to variable 6, was already discussed in the
previous section on \code{ida}.

\section{Methodological background}
Our proposed method consists of two major steps. In the first step, the
causal structure is estimated. This is done by estimating a graphical
model. A graphical model is a map of the dependence structure of the data
and can thus be an interesting object by itself. In the second step, we use
the estimated causal structure and the do-calculus [PEARL] to calculate
bounds on causal effects.

\subsection{Estimating graphical models}
Graphical models can be thought of as maps of dependence structures of a
given probability distribution or a sample thereof (see for example
\cite{lauritzen}). In order to illustrate the analogy, let us consider a
road map. In order to be able to use a road map, one needs two given
factors. Firstly, one needs the physical map with symbols such as dots and
lines. Secondly, one needs a rule for interpreting the symbols. For
instance, a railroad map and a map for electric circuits might look very
much alike, but their interpretation differs a lot. In the same sense, a
graphical model is a map. Firstly, a graphical model consists of a graph
with dots, lines and potentially arrowheads. Secondly, a graphical model
always comes with a rule for interpreting this graph. In general, nodes in
the graph represent (random) variables and edges represent some kind of
dependence.

\subsubsection{Without hidden and selection variables}
An example of a graphical model is the Directed Acyclic Graph (DAG)
model. The physical map here is a graph consisting of nodes and arrows
(only one arrowhead per line) connecting the nodes. As a further
restriction, the arrows must be directed in a way, so that it is not
possible to trace a circle when following the arrowheads. The
interpretation rule is d-separation, which is closely related to
conditional independence. This rule is a bit more intricate and we refer
the reader to \cite{lauritzen} for more details.

\begin{itemize}
\item Definition of DAG model; ref. to Lauritzen
\item Estimation methods: skeleton, pc; ref. to sgs, pc-paper
\end{itemize}
\subsubsection{With hidden or selection variables}
\begin{itemize}
\item AGs
\item Estimation method: fci; ref. to sgs, zhang (completeness)
\end{itemize}

\subsection{Estimating bounds on causal effects}
\subsubsection{Without hidden and selection variables}
\begin{itemize}
\item if causal structure was known: do-calculus of pearl; result by Shpitser
\item use GM as estimate for causal structure (causal markov property in pearl)
\item ambiguity due to equivalence class -> get only set of possible effects
\item local/global algorithm; equivalence; reference to Annals-paper
  \item example for application: see Nature Methods paper
\end{itemize}
\subsubsection{With hidden and selection variables}
estimating with latent variables present: not clear (?); perhaps cite
zhang paper on theoretical results? Leave out?

ASSUMPTIONS?

\section{Package pcalg}
Two goals: Estimate graphical models and bounds on causal effects; link
between the two; modularity in conditional independence tests; class as
output with methods (own chapter?). In the following, we discuss the major
functions of our package. Should I also mention that there are some
deprecated functions?
\subsection{skeleton}
Explain options.
\subsection{pc}
Explain options.
\subsection{ida}
Explain options.
\subsection{idaFast}
Explain options.
\subsection{fci}
Explain options.

\subsection{Estimating graphical models}
Running example for gaussian data.
\begin{itemize}
\item simulate graph and data set
\item use skeleton and pc
\item summarize and plot resulting object; vary linewidth
\item highlight modularity
\item mention predefined functions for oracle, discrete data, binary data
\end{itemize}

\subsection{Estimating bounds on causal effects}
Continue running example starting from pc object of last section.
\begin{itemize}
\item use \code{ida} to estimate one effect with both local and global method
\item use \code{idaFast} to compute effects on several x variables at the same time
\end{itemize}
\section{Conclusion}

\end{document}
